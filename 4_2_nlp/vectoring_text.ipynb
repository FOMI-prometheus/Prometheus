{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"vectoring_text.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"sFppbs7pdS4x","executionInfo":{"status":"ok","timestamp":1614428999811,"user_tz":0,"elapsed":887,"user":{"displayName":"N. E.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giu1R9ux2DYhWOwxiNijmyUYXnfk9yJqUCLNyq_vA=s64","userId":"01997527614154494135"}},"outputId":"51544d49-564b-4c60-a2a6-a3fc8ab8ef19"},"source":["import keras\n","import nltk\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","keras.__version__"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.4.3'"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"Zl6jSTm4dS5A"},"source":["# Text processing"]},{"cell_type":"markdown","metadata":{"id":"PleWMvTAdS5B"},"source":["First, we will look at simple operations with text: tokenisation, lemmatisation etc. We need them to make all words look similar to the machine.\n","\n","- Cleaning texts (regular expressions or one of the following)\n","- Tokenization is to break text into units (words and sentences) : \"I have a dog.\" --> \"I\", \"have\", \"a\", \"dog\", \".\"\n","- Stemming and lemmatization : reducing words into their common stem or lemma. \"has\" -> \"have\", \"dogs\" -> \"dog” etc.\n","- Removal of stop words ( common words such as “a” and “the” that appear in most documents but often provide no significant meaning)."]},{"cell_type":"code","metadata":{"id":"lSNfw4OzdS5C","executionInfo":{"status":"ok","timestamp":1614429002583,"user_tz":0,"elapsed":1137,"user":{"displayName":"N. E.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giu1R9ux2DYhWOwxiNijmyUYXnfk9yJqUCLNyq_vA=s64","userId":"01997527614154494135"}}},"source":["text = \"This is Felipe's class, isn't it?\""],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cuP9Z9tGdS5D"},"source":["You can use the following tokenizers to work with your text, depending on the task in hand:\n","- WhitespaceTokenizer\n","- TreebankWordTokenizer\n","- WordPunctTokenizer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FjI7ydjddS5D","executionInfo":{"status":"ok","timestamp":1614429003007,"user_tz":0,"elapsed":1001,"user":{"displayName":"N. E.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giu1R9ux2DYhWOwxiNijmyUYXnfk9yJqUCLNyq_vA=s64","userId":"01997527614154494135"}},"outputId":"22bf9ff3-62f2-4749-f650-2c5bad43c9cf"},"source":["#Tokenize a string on whitespace (space, tab, newline). You can use the string split() method instead.\n","tokenizer = nltk.tokenize.WhitespaceTokenizer()\n","tokenizer.tokenize(text)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['This', 'is', \"Felipe's\", 'class,', \"isn't\", 'it?']"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"BzsEtpemdS5D"},"source":["The Treebank tokenizer uses regular expressions to tokenize text as in Penn Treebank. \n","This is the method that is invoked by word_tokenize(). \n","It assumes that the text has already been segmented into sentences, e.g. using sent_tokenize().\n","\n","This tokenizer performs the following steps:\n","- split standard contractions, e.g. don't -> do n't and they'll -> they 'll\n","- treat most punctuation characters as separate tokens\n","- split off commas and single quotes, when followed by whitespace\n","- separate periods that appear at the end of line"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N_w6nYQidS5E","executionInfo":{"status":"ok","timestamp":1614429003008,"user_tz":0,"elapsed":557,"user":{"displayName":"N. E.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giu1R9ux2DYhWOwxiNijmyUYXnfk9yJqUCLNyq_vA=s64","userId":"01997527614154494135"}},"outputId":"74a8cb04-baba-42d4-8a69-5733eb521bc1"},"source":["tokenizer = nltk.tokenize.TreebankWordTokenizer()\n","tokenizer.tokenize(text)"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['This', 'is', 'Felipe', \"'s\", 'class', ',', 'is', \"n't\", 'it', '?']"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B0RulHwSdS5E","executionInfo":{"status":"ok","timestamp":1614429003384,"user_tz":0,"elapsed":703,"user":{"displayName":"N. E.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giu1R9ux2DYhWOwxiNijmyUYXnfk9yJqUCLNyq_vA=s64","userId":"01997527614154494135"}},"outputId":"181f9060-308b-4a7f-de1a-3f2412a970f5"},"source":["# Tokenize a text into a sequence of alphabetic and non-alphabetic characters, using the regexp \\w+|[^\\w\\s]+.\n","tokenizer = nltk.tokenize.WordPunctTokenizer()\n","tokenizer.tokenize(text)"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['This', 'is', 'Felipe', \"'\", 's', 'class', ',', 'isn', \"'\", 't', 'it', '?']"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"C08tg3wZdS5F"},"source":["Lemmatization and stemming: used for extracting lemma and stem of words\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"je944dpIdS5F","executionInfo":{"status":"ok","timestamp":1614429003733,"user_tz":0,"elapsed":572,"user":{"displayName":"N. E.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giu1R9ux2DYhWOwxiNijmyUYXnfk9yJqUCLNyq_vA=s64","userId":"01997527614154494135"}},"outputId":"1457c512-446c-4581-e291-d9d2738db73a"},"source":["text = \"feet wolves cats talked\"\n","tokenizer = nltk.tokenize.TreebankWordTokenizer()\n","tokens = tokenizer.tokenize(text)\n","print(tokens)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["['feet', 'wolves', 'cats', 'talked']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"ZKYOq726dS5G","executionInfo":{"status":"ok","timestamp":1614429004066,"user_tz":0,"elapsed":751,"user":{"displayName":"N. E.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giu1R9ux2DYhWOwxiNijmyUYXnfk9yJqUCLNyq_vA=s64","userId":"01997527614154494135"}},"outputId":"3bf1a6d9-569f-43f5-ce53-09d1afcdc616"},"source":["stemmer = nltk.stem.PorterStemmer()\n","\" \".join(stemmer.stem(token) for token in tokens)"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'feet wolv cat talk'"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"Jy_1QdB4dS5G"},"source":["# TFIDF\n","\n","In information retrieval, tf–idf or TFIDF, short for term **frequency–inverse document frequency**, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.\n","\n","It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling. The tf–idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general. tf–idf is one of the most popular term-weighting schemes.\n","\n","\n","In a large text corpus, some words will be very present (e.g. “the”, “a”, “is” in English) hence carrying very little meaningful information about the actual contents of the document. If we were to feed the direct count data directly to a classifier those very frequent terms would shadow the frequencies of rarer yet more interesting terms.\n","\n","In order to re-weight the count features into floating point values suitable for usage by a classifier it is very common to use the tf–idf transform. Read more [here](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction).\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"lKLa_4-2dS5G","executionInfo":{"status":"ok","timestamp":1614429005216,"user_tz":0,"elapsed":1555,"user":{"displayName":"N. E.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giu1R9ux2DYhWOwxiNijmyUYXnfk9yJqUCLNyq_vA=s64","userId":"01997527614154494135"}},"outputId":"bef12fc2-8693-474a-fd14-65a7ae3d5a6d"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","import pandas as pd\n","texts = [\n","    \"good movie\", \"not a good movie\", \"did not like\", \n","    \"i like it\", \"good one\"\n","]\n","# using default tokenizer in TfidfVectorizer\n","tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\n","features = tfidf.fit_transform(texts)\n","pd.DataFrame(\n","    features.todense(),\n","    columns=tfidf.get_feature_names()\n",")"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>good movie</th>\n","      <th>like</th>\n","      <th>movie</th>\n","      <th>not</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.707107</td>\n","      <td>0.000000</td>\n","      <td>0.707107</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.577350</td>\n","      <td>0.000000</td>\n","      <td>0.577350</td>\n","      <td>0.577350</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000000</td>\n","      <td>0.707107</td>\n","      <td>0.000000</td>\n","      <td>0.707107</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   good movie      like     movie       not\n","0    0.707107  0.000000  0.707107  0.000000\n","1    0.577350  0.000000  0.577350  0.577350\n","2    0.000000  0.707107  0.000000  0.707107\n","3    0.000000  1.000000  0.000000  0.000000\n","4    0.000000  0.000000  0.000000  0.000000"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"AetbB22pdS5H"},"source":["# One-hot encoding"]},{"cell_type":"code","metadata":{"id":"VJpGIlLadS5H","executionInfo":{"status":"ok","timestamp":1614429005217,"user_tz":0,"elapsed":1247,"user":{"displayName":"N. E.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giu1R9ux2DYhWOwxiNijmyUYXnfk9yJqUCLNyq_vA=s64","userId":"01997527614154494135"}}},"source":["from keras.preprocessing.text import Tokenizer\n","\n","samples = ['Mary has a ball', 'The dog ate my homework.']\n","\n","# We create a tokenizer, configured to only take\n","# into account the top-1000 most common words\n","tokenizer = Tokenizer(num_words=10)\n","# This builds the word index\n","tokenizer.fit_on_texts(samples)\n","\n","# This turns strings into lists of integer indices.\n","sequences = tokenizer.texts_to_sequences(samples)\n","\n","# You could also directly get the one-hot binary representations.\n","# Note that other vectorization modes than one-hot encoding are supported!\n","one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EJRDRJmIdS5H","executionInfo":{"status":"ok","timestamp":1614429005217,"user_tz":0,"elapsed":1055,"user":{"displayName":"N. E.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giu1R9ux2DYhWOwxiNijmyUYXnfk9yJqUCLNyq_vA=s64","userId":"01997527614154494135"}},"outputId":"1f771800-aea1-4e6b-a387-a1bae682d2d9"},"source":["one_hot_results[1]"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 0., 1., 1., 1., 1., 1.])"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"xQlVx6UsdS5I"},"source":["Try changing \"The\" in the second snetence to \"a\", the result will change. Why?"]},{"cell_type":"markdown","metadata":{"id":"1WrHZf5DdS5J"},"source":["# Using word embeddings\n","\n","Another popular and powerful way to associate a vector with a word is the use of dense \"word vectors\", also called \"word embeddings\". \n","While the vectors obtained through one-hot encoding are binary, sparse (mostly made of zeros) and very high-dimensional (same dimensionality as the number of words in the vocabulary), \"word embeddings\" are low-dimensional floating point vectors (i.e. \"dense\" vectors, as opposed to sparse vectors). \n","\n","Unlike word vectors obtained via one-hot encoding, word embeddings are learned from data. \n","Word embeddings pack more information into far fewer dimensions. "]},{"cell_type":"markdown","metadata":{"id":"7K0eiJmFdS5J"},"source":["There are two ways to obtain word embeddings:\n","\n","* Learn word embeddings jointly with the main task you care about (e.g. document classification or sentiment prediction). \n","In this setup, you would start with random word vectors, then learn your word vectors in the same way that you learn the weights of a neural network.\n","* Load into your model word embeddings that were pre-computed using a different machine learning task than the one you are trying to solve. \n","These are called \"pre-trained word embeddings\". \n","\n","Let's take a look at both."]},{"cell_type":"markdown","metadata":{"id":"0-zgh4sMdS5J"},"source":["## Learning word embeddings with the `Embedding` layer\n","\n","The geometric relationships between word vectors should reflect the semantic relationships between these words. \n","It is thus reasonable to __learn__ a new embedding space with every new task. Thankfully, backpropagation makes this really easy, and Keras makes it even easier. It's just about learning the weights of a layer: the `Embedding` layer."]},{"cell_type":"code","metadata":{"id":"j4adPpjddS5K","executionInfo":{"status":"ok","timestamp":1614429005542,"user_tz":0,"elapsed":461,"user":{"displayName":"N. E.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giu1R9ux2DYhWOwxiNijmyUYXnfk9yJqUCLNyq_vA=s64","userId":"01997527614154494135"}}},"source":["from keras.layers import Embedding\n","\n","# The Embedding layer takes at least two arguments:\n","# the number of possible tokens, here 1000 (1 + maximum word index),\n","# and the dimensionality of the embeddings, here 64.\n","embedding_layer = Embedding(1000, 64)\n"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-luHqRgSdS5K"},"source":["The `Embedding` layer is best understood as a dictionary mapping integer indices (which stand for specific words) to dense vectors. It takes \n","as input integers, it looks up these integers into an internal dictionary, and it returns the associated vectors. It's effectively a dictionary lookup.\n","\n","Let's apply this idea to the IMDB movie review sentiment prediction task that you are already familiar with. Let's quickly prepare \n","the data. We will restrict the movie reviews to the top 10,000 most common words (like we did the first time we worked with this dataset), \n","and cut the reviews after only 20 words. Our network will simply learn 8-dimensional embeddings for each of the 10,000 words, turn the \n","input integer sequences (2D integer tensor) into embedded sequences (3D float tensor), flatten the tensor to 2D, and train a single `Dense` \n","layer on top for classification."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hpgDRK1WdS5L","executionInfo":{"status":"ok","timestamp":1614429012525,"user_tz":0,"elapsed":6900,"user":{"displayName":"N. E.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giu1R9ux2DYhWOwxiNijmyUYXnfk9yJqUCLNyq_vA=s64","userId":"01997527614154494135"}},"outputId":"82ab9ca5-f62d-48d1-efbf-0ff330ffdc0f"},"source":["from keras.datasets import imdb\n","from keras import preprocessing\n","\n","# Number of words to consider as features\n","max_features = 10000\n","# Cut texts after this number of words \n","# (among top max_features most common words)\n","maxlen = 20\n","\n","# Load the data as lists of integers.\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n","\n","# This turns our lists of integers\n","# into a 2D integer tensor of shape `(samples, maxlen)`\n","x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n","x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ubNYGorjdS5L","executionInfo":{"status":"ok","timestamp":1614429012526,"user_tz":0,"elapsed":6568,"user":{"displayName":"N. E.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giu1R9ux2DYhWOwxiNijmyUYXnfk9yJqUCLNyq_vA=s64","userId":"01997527614154494135"}},"outputId":"6a1d6532-f9d4-436d-ce21-c945e516192b"},"source":["from keras.models import Sequential\n","from keras.layers import Flatten, Dense\n","\n","model = Sequential()\n","# We specify the maximum input length to our Embedding layer\n","# so we can later flatten the embedded inputs\n","model.add(Embedding(10000, 8, input_length=maxlen))\n","# After the Embedding layer, \n","# our activations have shape `(samples, maxlen, 8)`.\n","\n","# We flatten the 3D tensor of embeddings \n","# into a 2D tensor of shape `(samples, maxlen * 8)`\n","model.add(Flatten())\n","\n","# We add the classifier on top\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n","model.summary()"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_3 (Embedding)      (None, 20, 8)             80000     \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 160)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 161       \n","=================================================================\n","Total params: 80,161\n","Trainable params: 80,161\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O8Bwg2H-dS5L","executionInfo":{"status":"ok","timestamp":1614429022455,"user_tz":0,"elapsed":16049,"user":{"displayName":"N. E.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giu1R9ux2DYhWOwxiNijmyUYXnfk9yJqUCLNyq_vA=s64","userId":"01997527614154494135"}},"outputId":"8862ddc6-47cf-4289-bb66-1a8f47638f07"},"source":["history = model.fit(x_train, y_train,\n","                    epochs=10,\n","                    batch_size=32,\n","                    validation_split=0.2)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","625/625 [==============================] - 1s 2ms/step - loss: 0.6848 - acc: 0.5626 - val_loss: 0.6141 - val_acc: 0.6984\n","Epoch 2/10\n","625/625 [==============================] - 1s 2ms/step - loss: 0.5657 - acc: 0.7425 - val_loss: 0.5243 - val_acc: 0.7312\n","Epoch 3/10\n","625/625 [==============================] - 1s 2ms/step - loss: 0.4694 - acc: 0.7873 - val_loss: 0.4982 - val_acc: 0.7490\n","Epoch 4/10\n","625/625 [==============================] - 1s 1ms/step - loss: 0.4239 - acc: 0.8101 - val_loss: 0.4939 - val_acc: 0.7496\n","Epoch 5/10\n","625/625 [==============================] - 1s 1ms/step - loss: 0.3904 - acc: 0.8286 - val_loss: 0.4927 - val_acc: 0.7552\n","Epoch 6/10\n","625/625 [==============================] - 1s 2ms/step - loss: 0.3737 - acc: 0.8352 - val_loss: 0.4983 - val_acc: 0.7546\n","Epoch 7/10\n","625/625 [==============================] - 1s 1ms/step - loss: 0.3482 - acc: 0.8494 - val_loss: 0.5016 - val_acc: 0.7574\n","Epoch 8/10\n","625/625 [==============================] - 1s 1ms/step - loss: 0.3311 - acc: 0.8620 - val_loss: 0.5076 - val_acc: 0.7578\n","Epoch 9/10\n","625/625 [==============================] - 1s 1ms/step - loss: 0.3133 - acc: 0.8705 - val_loss: 0.5171 - val_acc: 0.7542\n","Epoch 10/10\n","625/625 [==============================] - 1s 2ms/step - loss: 0.2956 - acc: 0.8801 - val_loss: 0.5233 - val_acc: 0.7552\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOd0c3hJdS5M","executionInfo":{"status":"ok","timestamp":1614429023341,"user_tz":0,"elapsed":16520,"user":{"displayName":"N. E.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giu1R9ux2DYhWOwxiNijmyUYXnfk9yJqUCLNyq_vA=s64","userId":"01997527614154494135"}},"outputId":"4b1e0175-ee38-40a8-ac4a-0b873230d971"},"source":["test_loss, test_acc = model.evaluate(x_test, y_test)\n","\n","print('\\nTest accuracy:', test_acc)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["782/782 [==============================] - 1s 943us/step - loss: 0.5114 - acc: 0.7608\n","\n","Test accuracy: 0.7608000040054321\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wud5ZtljdS5M"},"source":["We get to a validation accuracy of ~75%, which is pretty good considering that we only look at the first 20 words in every review. But \n","note that merely flattening the embedded sequences and training a single `Dense` layer on top leads to a model that treats each word in the \n","input sequence separately, without considering inter-word relationships and structure sentence (e.g. it would likely treat both _\"this movie \n","is shit\"_ and _\"this movie is the shit\"_ as being negative \"reviews\"). It would be much better to add recurrent layers or 1D convolutional \n","layers on top of the embedded sequences to learn features that take into account each sequence as a whole. That's what we will focus on in \n","the next few sections."]},{"cell_type":"markdown","metadata":{"id":"FKoJFRvXdS5N"},"source":["# Plot the training history"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"id":"P3cXYTbodS5N","executionInfo":{"status":"ok","timestamp":1614429023342,"user_tz":0,"elapsed":14860,"user":{"displayName":"N. E.","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giu1R9ux2DYhWOwxiNijmyUYXnfk9yJqUCLNyq_vA=s64","userId":"01997527614154494135"}},"outputId":"420e3668-925e-43b7-c21d-8a8e35a2cecc"},"source":["print(history.history.keys())\n","plt.plot(history.history['acc'])\n","plt.title('Model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"execution_count":32,"outputs":[{"output_type":"stream","text":["dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"Em5AQT_wdoXq"},"source":[""],"execution_count":null,"outputs":[]}]}